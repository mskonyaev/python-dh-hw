{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ3\n",
    "## Задание 1\n",
    "Напишите функцию, которая будет читать файл, лемматизировать текст с помощью pymystem3 и записывать результат в новый файл.\n",
    "У функции должно бы два аргумента: путь к исходному файлу и путь к файлу с лемматизированным текстом. Вызов функции тоже должен быть прописан в решении.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem \n",
    "from string import punctuation\n",
    "m = Mystem()\n",
    "def open_function(path_to_file, path_to_new_file):\n",
    "    all_text = []\n",
    "    with open(path_to_file, 'r', encoding = 'utf-8') as old_file: \n",
    "        for line in old_file:\n",
    "            #удаление пунктуации\n",
    "            line = line.split()\n",
    "            stripped_line = []\n",
    "            for a in line:\n",
    "                a = a.strip(punctuation)\n",
    "                all_text.append(a)               \n",
    "    #лемматизация\n",
    "    all_text = \" \".join(all_text)            \n",
    "    lemmas = m.lemmatize(all_text)\n",
    "    #запись лемм в новый файл\n",
    "    with open(path_to_new_file, 'w', encoding = 'utf-8') as new_file:\n",
    "        lemmas = \" \".join(lemmas)\n",
    "        new_file.write(lemmas)   \n",
    "\n",
    "#вызов функции \n",
    "path_to_file = 'literary_anecdotes.txt' \n",
    "path_to_new_file = 'lemmatized_literary_anecdotes.txt' \n",
    "open_function(path_to_file, path_to_new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "Очистите лемматизированный текст от стоп-слов и посчитайте ipm для оставшихся. Выведите 20 самых частотных по этому параметру слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем список стоп слов из файла с стоп словами\n",
    "stop_words = []\n",
    "prepared_text_list = []\n",
    "with open('stop_words.txt', 'r', encoding = 'utf-8') as new_file:\n",
    "    for line in new_file:\n",
    "        line = line.rstrip('\\n')\n",
    "        stop_words.append(line)\n",
    "#удаляем стоп слова и оставшиеся дефисы из лемматизированного текста        \n",
    "with open(path_to_new_file, 'r', encoding = 'utf-8') as new_file:\n",
    "    for line in new_file:\n",
    "        line = line.split()\n",
    "        for word in line:\n",
    "            if word in stop_words: continue\n",
    "            elif word == '-': continue    \n",
    "            else:\n",
    "                with open('prepared_text.txt', 'a', encoding = 'utf-8') as prepared_text:\n",
    "                    prepared_text.write(word)\n",
    "                    prepared_text.write('\\n')\n",
    "                    #создаем список лемматизированных слов без стоп слов\n",
    "                    prepared_text_list.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('пушкин', 35456.730769230766), ('толстой', 19831.73076923077), ('гоголь', 18629.80769230769), ('однажды', 17427.884615384617), ('лев', 15024.038461538463), ('любить', 12019.23076923077), ('достоевский', 12019.23076923077), ('тургенев', 9615.384615384615), ('ребенок', 9014.423076923076), ('царствие', 9014.423076923076), ('небесный', 9014.423076923076), ('окно', 7211.538461538462), ('тверской', 7211.538461538462), ('бульвар', 7211.538461538462), ('приходить', 7211.538461538462), ('лермонтов', 7211.538461538462), ('федор', 6610.576923076923), ('михайлович', 6610.576923076923), ('идти', 6009.615384615385)]\n"
     ]
    }
   ],
   "source": [
    "#считаем ipm                    \n",
    "counts = {}\n",
    "for word in prepared_text_list:\n",
    "    counts[word] = counts.get(word, 0) + 1\n",
    "#считаем ipm    \n",
    "for x in counts: counts[x] = counts[x]/len(prepared_text_list)*1000000    \n",
    "sorted_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_counts_20 = sorted_counts[:19]\n",
    "#выводим 20 слов с самым большим ipm\n",
    "print(sorted_counts_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "Сделайте полный морфологический разбор исходного текста. Напишите регулярное выражение, которое будет извлекать из тега только часть речи. Пройдитесь циклом по списку с разборами, который выдал pymystem3, извлекая из каждого разбора форму слова и его часть речи и записывая их в новый словарь (форма -- ключ, часть речи -- значение).Посчитайте абсолютную частоту для всех частей речи, а затем относительнную частоту (абсолютная частота / длина текста в словах)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem \n",
    "from string import punctuation \n",
    "import re\n",
    "all_text_list = []\n",
    "c = 0\n",
    "with open('literary_anecdotes.txt', 'r', encoding = 'utf-8') as old_file:\n",
    "    for line in old_file:\n",
    "        #удаляем пункутацию и делаем список из всего текста\n",
    "        line = line.split()\n",
    "        for a in line:\n",
    "            a = a.strip(punctuation)\n",
    "            all_text_list.append(a)\n",
    "for line in all_text_list:\n",
    "    if line == '-': all_text_list.remove(line)\n",
    "#морфологический разбор\n",
    "m = Mystem()\n",
    "analyzed_elements = {}\n",
    "all_text = \" \".join(all_text_list)\n",
    "y = m.analyze(all_text)\n",
    "for x in y:\n",
    "    try: \n",
    "        analysis = x['analysis']\n",
    "        text = x['text']\n",
    "        for a in analysis:\n",
    "            try: \n",
    "                gr = a['gr']\n",
    "                pattern = re.compile('^[A-Z]*')\n",
    "                gr = pattern.findall(gr)\n",
    "                analyzed_elements[text] = \"\".join(gr)\n",
    "            except: pass \n",
    "    except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Абсолютная частота [('S', 442), ('V', 435), ('A', 99), ('ADV', 86), ('SPRO', 54), ('APRO', 50), ('PR', 37), ('PART', 28), ('ADVPRO', 24), ('CONJ', 22), ('NUM', 9), ('INTJ', 7), ('ANUM', 2)]\n",
      "Относительная частота {'S': 0.1556338028169014, 'V': 0.15316901408450703, 'A': 0.03485915492957747, 'ADV': 0.03028169014084507, 'SPRO': 0.019014084507042252, 'APRO': 0.017605633802816902, 'PR': 0.013028169014084507, 'PART': 0.009859154929577466, 'ADVPRO': 0.008450704225352112, 'CONJ': 0.007746478873239437, 'NUM': 0.0031690140845070424, 'INTJ': 0.0024647887323943664, 'ANUM': 0.0007042253521126761}\n"
     ]
    }
   ],
   "source": [
    "pos_counter = []\n",
    "for key in analyzed_elements:\n",
    "    value = analyzed_elements[key]\n",
    "    pos_counter.append(value)\n",
    "pos_counts = {}    \n",
    "for x in pos_counter:\n",
    "    pos_counts[x] = pos_counts.get(x, 0) + 1\n",
    "#абсолютная\n",
    "sorted_pos_counts = sorted(pos_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Абсолютная частота\", sorted_pos_counts)\n",
    "#относительная\n",
    "otn = {}\n",
    "for x in sorted_pos_counts:\n",
    "    key = x[0]\n",
    "    value = x[1]/len(all_text_list)  \n",
    "    otn[key] = value\n",
    "print(\"Относительная частота\", otn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
